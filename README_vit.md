# Vision Transformer vs CNN: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞ CIFAR-10

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–µ–∞–ª–∏–∑—É–µ—Ç –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å Vision Transformer (ViT) –∏ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (CNN) –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ CIFAR-10.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
‚îú‚îÄ‚îÄ vision_transformer_comparison.py   # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ vision_transformer_notebook.ipynb  # Jupyter Notebook —Å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
‚îú‚îÄ‚îÄ requirements_vit.txt               # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
‚îî‚îÄ‚îÄ README_vit.md                      # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements_vit.txt
```

### –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

```bash
python vision_transformer_comparison.py
```

### –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑

```bash
jupyter notebook vision_transformer_notebook.ipynb
```

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–µ–π

### Vision Transformer (ViT)
- **Patch Embedding**: –†–∞–∑–±–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 32x32 –Ω–∞ –ø–∞—Ç—á–∏ 4x4
- **Multi-Head Attention**: 3 –≥–æ–ª–æ–≤—ã –≤–Ω–∏–º–∞–Ω–∏—è —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ 192
- **Transformer Blocks**: 12 —Å–ª–æ–µ–≤ —Å MLP ratio 4
- **Classification Head**: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ [CLS] —Ç–æ–∫–µ–Ω–∞

### CNN Classifier
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è CNN —Å BatchNorm –∏ ReLU
- **–ë–ª–æ–∫–∏**: 4 —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–∞ —Å MaxPooling
- **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä**: –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏ —Å Dropout

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

| –ú–æ–¥–µ–ª—å | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è | –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ |
|--------|-----------|---------------|------------------|
| Vision Transformer | 5,362,762 | 421.11—Å | 77.54% |
| CNN | 4,823,114 | 177.97—Å | 91.33% |

## üîç –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

### Vision Transformer
‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –∫–æ –≤—Å–µ–º —á–∞—Å—Ç—è–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –•–æ—Ä–æ—à–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö
- –ú–µ–Ω—å—à–µ –∏–Ω–¥—É–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π

‚ùå **–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
- –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –Ω–∞ –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
- –ú–µ–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –±–µ–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è

### CNN
‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
- –ë—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
- –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–æ–Ω–Ω–∞—è –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å

‚ùå **–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ —Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ
- –°–∏–ª—å–Ω—ã–µ –∏–Ω–¥—É–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

- **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CNN** –¥–ª—è –∑–∞–¥–∞—á —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
- **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π ViT** –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- **–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≥–∏–±—Ä–∏–¥–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã** –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤

## üõ†Ô∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
- **Batch size**: 128
- **Epochs**: 30
- **Learning rate**: 0.001
- **Optimizer**: AdamW –¥–ª—è ViT, Adam –¥–ª—è CNN
- **Scheduler**: CosineAnnealingLR –¥–ª—è ViT, StepLR –¥–ª—è CNN

### –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
- RandomCrop(32, padding=4)
- RandomHorizontalFlip()
- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏—è–º CIFAR-10

## üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

–°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç:
- –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ—Ç–µ—Ä—å –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —ç–ø–æ—Ö—É
- –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π

## üîß –ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è

–í—ã –º–æ–∂–µ—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–µ–π –≤ —Ñ—É–Ω–∫—Ü–∏–∏ `main()`:

```python
# ViT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
vit_model = VisionTransformer(
    img_size=32,
    patch_size=4,
    embed_dim=192,
    depth=12,
    num_heads=3,
    ...
)
```

## üìö –õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞

- Dosovitskiy, A., et al. "An image is worth 16x16 words: Transformers for image recognition at scale." ICLR 2021.
- He, K., et al. "Deep residual learning for image recognition." CVPR 2016.

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:
1. –°–æ–∑–¥–∞–π—Ç–µ issue
2. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ pull request
3. –ü–æ–¥–µ–ª–∏—Ç–µ—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

---

**–ê–≤—Ç–æ—Ä**: –°—Ç—É–¥–µ–Ω—Ç  
**–î–∞—Ç–∞**: 2025-06-05  
**–ö—É—Ä—Å**: –ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ 